{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "!pip install split-folders\n",
        "import splitfolders\n",
        "\n",
        "from tensorflow.keras.applications import EfficientNetB0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tEWmTf4KaVx5",
        "outputId": "929301b8-422e-4d31-f053-7c446a2fb037"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: split-folders in /usr/local/lib/python3.10/dist-packages (0.5.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = \"sortedData\"\n",
        "splitfolders.ratio('/content/drive/MyDrive/coffee/coffeedataset40', output=output, seed=42, ratio=(0.7, 0.15, 0.15))\n",
        "train_dir = \"sortedData/train\"\n",
        "test_dir = \"sortedData/test\"\n",
        "val_dir = \"sortedData/val\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EFxXcwiBaXcC",
        "outputId": "07c842fd-cc32-4eca-b61b-aef6bf8f5602"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Copying files: 80 files [00:15,  5.11 files/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5\n",
        "NUM_CLASSES = 2\n",
        "model_save_location = \"Model/EfficientNet\""
      ],
      "metadata": {
        "id": "YwLbbeXJbtR6"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_augmentation = Sequential(\n",
        "    [\n",
        "        preprocessing.RandomRotation(factor=0.15),\n",
        "        preprocessing.RandomTranslation(height_factor=0.1, width_factor=0.1),\n",
        "        preprocessing.RandomFlip(),\n",
        "        preprocessing.RandomContrast(factor=0.1),\n",
        "    ],\n",
        "    name=\"img_augmentation\",\n",
        ")\n",
        "\n",
        "def build_model(NUM_CLASSES):\n",
        "    inputs = layers.Input(shape=(224, 224, 3))\n",
        "    x = img_augmentation(inputs)\n",
        "\n",
        "    #Using the imported version of EfficientNet\n",
        "    model = EfficientNetB0(include_top=False, input_tensor=x, weights=\"imagenet\")\n",
        "\n",
        "    # Freeze the pretrained weights\n",
        "    model.trainable = False\n",
        "\n",
        "    # Rebuild top\n",
        "    x = layers.GlobalAveragePooling2D(name=\"avg_pool\")(model.output)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    top_dropout_rate = 0.2\n",
        "    x = layers.Dropout(top_dropout_rate, name=\"top_dropout\")(x)\n",
        "    outputs = layers.Dense(NUM_CLASSES, activation=\"softmax\", name=\"pred\")(x)\n",
        "\n",
        "    # Compile\n",
        "    model = tf.keras.Model(inputs, outputs, name=\"EfficientNet\")\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-2)\n",
        "    model.compile(\n",
        "        optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
        "    )\n",
        "    return model\n",
        "\n",
        "def unfreeze_model(model):\n",
        "    # We unfreeze the top 20 layers while leaving BatchNorm layers frozen\n",
        "    for layer in model.layers[-20:]:\n",
        "        if not isinstance(layer, layers.BatchNormalization):\n",
        "            layer.trainable = True\n",
        "\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
        "    model.compile(\n",
        "        optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
        "    )"
      ],
      "metadata": {
        "id": "LzTBvfPTb4g9"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model(NUM_CLASSES)\n",
        "unfreeze_model(model)\n",
        "\n",
        "train_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.efficientnet.preprocess_input).flow_from_directory(\n",
        "    directory=train_dir, target_size=(224,224), batch_size=10)\n",
        "valid_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.efficientnet.preprocess_input).flow_from_directory(\n",
        "    directory=val_dir, target_size=(224,224), batch_size=10)\n",
        "test_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.efficientnet.preprocess_input).flow_from_directory(\n",
        "    directory=test_dir, target_size=(224,224), batch_size=10, shuffle=False)\n",
        "\n",
        "_ = model.fit(train_batches, epochs=epochs, validation_data=valid_batches, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B1oit2rcb9EN",
        "outputId": "f93a9837-66b3-4d3f-87ec-4e780d5d2030"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
            "16705208/16705208 [==============================] - 0s 0us/step\n",
            "Found 777 images belonging to 2 classes.\n",
            "Found 171 images belonging to 2 classes.\n",
            "Found 176 images belonging to 2 classes.\n",
            "Epoch 1/5\n",
            "78/78 [==============================] - 58s 647ms/step - loss: 0.2588 - accuracy: 0.8932 - val_loss: 0.1497 - val_accuracy: 0.9766\n",
            "Epoch 2/5\n",
            "78/78 [==============================] - 52s 666ms/step - loss: 0.0908 - accuracy: 0.9665 - val_loss: 0.0396 - val_accuracy: 1.0000\n",
            "Epoch 3/5\n",
            "78/78 [==============================] - 51s 653ms/step - loss: 0.0980 - accuracy: 0.9601 - val_loss: 0.0180 - val_accuracy: 1.0000\n",
            "Epoch 4/5\n",
            "78/78 [==============================] - 52s 669ms/step - loss: 0.0470 - accuracy: 0.9794 - val_loss: 0.0064 - val_accuracy: 1.0000\n",
            "Epoch 5/5\n",
            "78/78 [==============================] - 48s 613ms/step - loss: 0.0711 - accuracy: 0.9717 - val_loss: 0.0114 - val_accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Testing the Model\n",
        "test_labels = test_batches.classes\n",
        "print(\"Test Labels\",test_labels)\n",
        "print(test_batches.class_indices)\n",
        "\n",
        "predictions = model.predict(test_batches,steps=len(test_batches),verbose=0)\n",
        "\n",
        "acc = 0\n",
        "for i in range(len(test_labels)):\n",
        "    actual_class = test_labels[i]\n",
        "    if predictions[i][actual_class] > 0.5 : \n",
        "        acc += 1\n",
        "print(\"Accuracy:\",(acc/len(test_labels))*100,\"%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YUM_t-VPcUrx",
        "outputId": "8277c155-e326-42e1-df7b-6d5f74771f93"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Labels [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "{'darkbean': 0, 'espresso': 1}\n",
            "Accuracy: 100.0 %\n"
          ]
        }
      ]
    }
  ]
}